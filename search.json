[{"title":"一个推荐","url":"%2F2020%2F03%2F29%2F%E4%B8%80%E4%B8%AA%E6%8E%A8%E8%8D%90.html","content":"# 一个推荐\n\n## 没了这个我好像不会上网了\n\n> 谁说过一件难过的事情最多持续几天，因为后面会有更难的事\n\n最近因为pandownload的维护很多资料都不太好找，无意间发现了一个很牛逼的插件\n\n`Tampermonkey` 俗称‘油猴’，是一款浏览器插件管理器。可以安装一些网友开发的强大的浏览器插件。\n\n举例：全网音乐下载播放，全网视频，百度去光告，自定义页面，百度云增加全网盘搜索功能，不过他的搜索引擎貌似没有度盘搜好用。\n\n1. 插件安装[百度云提取码：ejzd](https://pan.baidu.com/s/1znXdqdQ5-LepdB9gE6CPgw )\n\n谷歌浏览器 设置 =>扩展程序 文件拖进去即可\n\n2. 插件安装\n\n[点我查找](https://greasyfork.org/zh-CN)，在这个网站寻找需要的就好啦，安装即生效很方便\n\n3. 推荐 \n\n   屏幕保护，百度云，vip音乐，vip视频解析，去广告\n\n4. 我安装的图\n\n![image-20200329173353526](一个推荐/wallhaven-248751.png)"},{"title":"那些实战的演练","url":"%2F2020%2F03%2F29%2F%E9%82%A3%E4%BA%9B%E5%AE%9E%E6%88%98%E7%9A%84%E6%BC%94%E7%BB%83.html","content":"# nginx 那些实战的演练\n\n> 转身的寥寥笑脸，不甘的甘愿\n\n## 1.架构设置\n\n流量分发：在分发层的nginx实施\n\n多级缓存架构的控制逻辑：在应用层的nginx实施\n\n热点数据的自动降级，也写在分发层\n\n1. 第一个nginx作为应用层\n\n（1）部署openresty\n\n```lua\nmkdir -p /usr/servers  \ncd /usr/servers/\n\nyum install -y readline-devel pcre-devel openssl-devel gcc\n\nwget http://openresty.org/download/ngx_openresty-1.7.7.2.tar.gz  \ntar -xzvf ngx_openresty-1.7.7.2.tar.gz  \ncd /usr/servers/ngx_openresty-1.7.7.2/\n\ncd bundle/LuaJIT-2.1-20150120/  \nmake clean && make && make install  \nln -sf luajit-2.1.0-alpha /usr/local/bin/luajit\n\ncd bundle  \nwget https://github.com/FRiCKLE/ngx_cache_purge/archive/2.3.tar.gz  \ntar -xvf 2.3.tar.gz  \n\ncd bundle  \nwget https://github.com/yaoweibin/nginx_upstream_check_module/archive/v0.3.0.tar.gz  \ntar -xvf v0.3.0.tar.gz  \n\ncd /usr/servers/ngx_openresty-1.7.7.2  \n./configure --prefix=/usr/servers --with-http_realip_module  --with-pcre  --with-luajit --add-module=./bundle/ngx_cache_purge-2.3/ --add-module=./bundle/nginx_upstream_check_module-0.3.0/ -j2  \nmake && make install \n\ncd /usr/servers/  \nll\n\n/usr/servers/luajit\n/usr/servers/lualib\n/usr/servers/nginx\n/usr/servers/nginx/sbin/nginx -V \n```\n\n常用的设置\n\n```\n/usr/servers/nginx/sbin/nginx -t  #检测\n/usr/servers/nginx/sbin/nginx     #启动\n/usr/servers/nginx/sbin/nginx -s reload  #重启\ntail -f /usr/servers/nginx/logs/error.log #查看异常日志\n```\n\n代码\n\n```lua\n项目工程结构\n\nhello\n    hello.conf     \n    lua              \n      hello.lua\n    lualib            \n      *.lua\n      *.so\n\n放在/usr/hello目录下\n\n/usr/servers/nginx/conf/nginx.conf\n\nworker_processes  2;  \n\nerror_log  logs/error.log;  \n\nevents {  \n    worker_connections  1024;  \n}  \n\nhttp {  \n    include       mime.types;  \n    default_type  text/html;  \n  \n    lua_package_path \"/usr/hello/lualib/?.lua;;\";  \n    lua_package_cpath \"/usr/hello/lualib/?.so;;\"; \n    include /usr/hello/hello.conf;  \n}  \n\n/usr/hello/hello.conf\n\nserver {  \n    listen       80;  \n    server_name  _;  \n  \n    location /lua {  \n        default_type 'text/html';  \n        lua_code_cache off;  \n        content_by_lua_file /usr/example/lua/test.lua;  \n    }  \n}  \n\n```\n\n## 2.基于id的流量分发\n\n1、获取请求参数，比如productId\n2、对productId进行hash\n3、hash值对应用服务器数量取模，获取到一个应用服务器\n4、利用http发送请求到应用层nginx\n5、获取响应后返回\n\n首先引入lua http lib包\n\nwget https://raw.githubusercontent.com/pintsized/lua-resty-http/master/lib/resty/http_headers.lua  \nwget https://raw.githubusercontent.com/pintsized/lua-resty-http/master/lib/resty/http.lua \n\n代码：\n\n```\nlocal uri_args = ngx.req.get_uri_args()\nlocal productId = uri_args[\"productId\"]\n\nlocal host = {\"192.168.31.19\", \"192.168.31.187\"}\nlocal hash = ngx.crc32_long(productId)\nhash = (hash % 2) + 1  \nbackend = \"http://\"..host[hash]\n\nlocal method = uri_args[\"method\"]\nlocal requestBody = \"/\"..method..\"?productId=\"..productId\n\nlocal http = require(\"resty.http\")  \nlocal httpc = http.new()  \n\nlocal resp, err = httpc:request_uri(backend, {  \n    method = \"GET\",  \n    path = requestBody\n})\n\nif not resp then  \n    ngx.say(\"request error :\", err)  \n    return  \nend\n\nngx.say(resp.body)  \n  \nhttpc:close() \n```\n\n```lua\nlocal url_args = ngx.req.get_uri_args\nlocal productId = url_args[\"productId\"]\nlocal host =[1,2]\nlocal hash = ngx.crc32_long(productId)\nlocal index = hash%2 +1\nbackend = \"http://\"..host[index]\nlocal menthod = url_args[\"method\"]\nlocal requesBody = \"/\"..menthod..\"?productId=\"..productId\nlocal http = require(\"resty.http\")\nlocal httpc = http.new\nlcoal resq ,err =httpc:request_url(backed,{\n        menthod=\"GET\",\n        path=requestBody\n    })\nif not resq then\n    ngx.say(\"req error :\",err)\n    return\n    end\nngx.say(resq.body)\nhttpc:close()\n/usr/servers/nginx/sbin/nginx -s reload\n```\n\nnginx缓存\n\n```lua\n\n分发层nginx，lua应用，会将商品id，商品店铺id，都转发到后端的应用nginx\n\n/usr/servers/nginx/sbin/nginx -s reload\n\n1、应用nginx的lua脚本接收到请求\n\n2、获取请求参数中的商品id，以及商品店铺id\n\n3、根据商品id和商品店铺id，在nginx本地缓存中尝试获取数据\n\n4、如果在nginx本地缓存中没有获取到数据，那么就到redis分布式缓存中获取数据，如果获取到了数据，还要设置到nginx本地缓存中\n\n但是这里有个问题，建议不要用nginx+lua直接去获取redis数据\n\n因为openresty没有太好的redis cluster的支持包，所以建议是发送http请求到缓存数据生产服务，由该服务提供一个http接口\n\n缓存数生产服务可以基于redis cluster api从redis中直接获取数据，并返回给nginx\n\ncd /usr/hello/lualib/resty/  \nwget https://raw.githubusercontent.com/pintsized/lua-resty-http/master/lib/resty/http_headers.lua  \nwget https://raw.githubusercontent.com/pintsized/lua-resty-http/master/lib/resty/http.lua \n\n5、如果缓存数据生产服务没有在redis分布式缓存中没有获取到数据，那么就在自己本地ehcache中获取数据，返回数据给nginx，也要设置到nginx本地缓存中\n\n6、如果ehcache本地缓存都没有数据，那么就需要去原始的服务中拉去数据，该服务会从mysql中查询，拉去到数据之后，返回给nginx，并重新设置到ehcache和redis中\n\n这里先不考虑，后面要专门讲解一套分布式缓存重建并发冲突的问题和解决方案\n\n7、nginx最终利用获取到的数据，动态渲染网页模板\n\ncd /usr/hello/lualib/resty/\nwget https://raw.githubusercontent.com/bungle/lua-resty-template/master/lib/resty/template.lua\nmkdir /usr/hello/lualib/resty/html\ncd /usr/hello/lualib/resty/html\nwget https://raw.githubusercontent.com/bungle/lua-resty-template/master/lib/resty/template/html.lua\n\n在hello.conf的server中配置模板位置\n\nset $template_location \"/templates\";  \nset $template_root \"/usr/hello/templates\";\n\nmkdir /usr/hello/templates\n\nvi product.html\n\nproduct id: {* productId *}<br/>\nproduct name: {* productName *}<br/>\nproduct picture list: {* productPictureList *}<br/>\nproduct specification: {* productSpecification *}<br/>\nproduct service: {* productService *}<br/>\nproduct color: {* productColor *}<br/>\nproduct size: {* productSize *}<br/>\nshop id: {* shopId *}<br/>\nshop name: {* shopName *}<br/>\nshop level: {* shopLevel *}<br/>\nshop good cooment rate: {* shopGoodCommentRate *}<br/>\n\n8、将渲染后的网页模板作为http响应，返回给分发层nginx\n\nhello.conf中：\n\nlua_shared_dict my_cache 128m;\n\nlua脚本中：\n\nlocal uri_args = ngx.req.get_uri_args()\nlocal productId = uri_args[\"productId\"]\nlocal shopId = uri_args[\"shopId\"]\n\nlocal cache_ngx = ngx.shared.my_cache\n\nlocal productCacheKey = \"product_info_\"..productId\nlocal shopCacheKey = \"shop_info_\"..shopId\n\nlocal productCache = cache_ngx:get(productCacheKey)\nlocal shopCache = cache_ngx:get(shopCacheKey)\n\nif productCache == \"\" or productCache == nil then\n\tlocal http = require(\"resty.http\")\n\tlocal httpc = http.new()\n\n\tlocal resp, err = httpc:request_uri(\"http://192.168.31.179:8080\",{\n  \t\tmethod = \"GET\",\n  \t\tpath = \"/getProductInfo?productId=\"..productId\n\t})\n\n\tproductCache = resp.body\n\tcache_ngx:set(productCacheKey, productCache, 10 * 60)\nend\n\nif shopCache == \"\" or shopCache == nil then\n\tlocal http = require(\"resty.http\")\n\tlocal httpc = http.new()\n\n\tlocal resp, err = httpc:request_uri(\"http://192.168.31.179:8080\",{\n  \t\tmethod = \"GET\",\n  \t\tpath = \"/getShopInfo?shopId=\"..shopId\n\t})\n\n\tshopCache = resp.body\n\tcache_ngx:set(shopCacheKey, shopCache, 10 * 60)\nend\n\nlocal cjson = require(\"cjson\")\nlocal productCacheJSON = cjson.decode(productCache)\nlocal shopCacheJSON = cjson.decode(shopCache)\n\nlocal context = {\n\tproductId = productCacheJSON.id,\n\tproductName = productCacheJSON.name,\n\tproductPrice = productCacheJSON.price,\n\tproductPictureList = productCacheJSON.pictureList,\n\tproductSpecification = productCacheJSON.specification,\n\tproductService = productCacheJSON.service,\n\tproductColor = productCacheJSON.color,\n\tproductSize = productCacheJSON.size,\n\tshopId = shopCacheJSON.id,\n\tshopName = shopCacheJSON.name,\n\tshopLevel = shopCacheJSON.level,\n\tshopGoodCommentRate = shopCacheJSON.goodCommentRate\n}\n\nlocal template = require(\"resty.template\")\ntemplate.render(\"product.html\", context)\n\n```\n\n","tags":["nginx"],"categories":["nginx"]},{"title":"nginx学习笔记（2）","url":"%2F2020%2F03%2F29%2Fnginx%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89.html","content":"#`nginx`学习笔记  (二)\n\n> 时钟在走，时光飞逝，我失去了船，得到了宝藏，也失去了你。\n\n## 1. `openResty`安装\n\n==TODO\n\n## 2. hello_world\n\nnginx 如何嵌入 lua 脚本。方法就是在nginx的配置文件nginx.conf 中使用 content_by_lua 或者 cotent_by_lua_file 指令：\n\n1.  content_by_lua 一般在很简单的lua脚本时使用\n\n```javascript\n        location /lua {\n                set $test \"hello, world.\";\n                content_by_lua '\n                        ngx.header.content_type = \"text/plain\";\n                        ngx.say(ngx.var.test);\n                ';\n        }\n\n```\n\nngx.say 就是打印出hello，world，本来就是c写的\n\n2. cotent_by_lua_file 适应于复杂的 lua 脚本，专门放入一个文件中：\n\n```\nlocalition /lua{\n content_by_lua_file lua/hello.lua\n}\n```\n\n3. lua访问redis\n\n```\nlcoaltion /test_redis{\ncontent_by_lua_file lua/test_redis.lua\n}\n```\n\ncat test_redis.lua\n\n```c\nlocal redis = requre \"resty.redis\"\nlocal red = redis :new()\nred.set_timeout(1000)\nlocal ok,err =red:connect(\"127.0.0.1\",6379)\nif not ok then\n    \tngx.say(\"fail to connect\",err)\n    return\nend\nngx.say(\"result\",ok)\n local res,err=red:get(\"dog\") \n  if not res then\n      ngx.say(\"failed to get doy: \",err)\n   return\n   end\n  if res == ngx.null then  \n     ngx.say(\"dog not found\")\n   return\n   end\n   ngx.say(\"dog: \", res)   \n```\n\n## 3. 访问mysql\n\n```mysql\n[root@localhost lua]# pwd\n/opt/openresty/nginx/lua\n[root@localhost lua]# cat mysql_test.lua\nlocal mysql = require \"resty.mysql\"\nlocal db, err = mysql:new()\n\nif not db then\n        ngx.say(\"failed to instantiate mysql: \", err)\n        return\nend\n\ndb:set_timeout(1000)\n\nlocal ok, err, errno, sqlstate = db:connect{\n        host = \"127.0.0.1\",\n        port = 3306,\n        database = \"ngx_lua\",\n        user = \"root\",\n        password=\"digdeep\",\n        max_packet_size = 1024 * 1024\n}\n\nif not ok then\n        ngx.say(\"failed to connect: \", err, \": \", errno, \" \", sqlstate)\n        return\nend\n\nngx.say(\"connected to mysql.\")\n\nlocal res, err, errno, sqlstate = db:query(\"drop table if exists cats\")\nif not res then\n        ngx.say(\"bad result: \", err, \": \", errno, \": \", sqlstate, \".\")\n        return\nend\n\nres, err, errno, sqlstate = db:query(\"create table cats \" .. \"(id int not null primary key auto_increment, \"\n                                        .. \"name varchar(30))\")\nif not res then\n        ngx.say(\"bad result: \", err, \": \", errno, \": \", sqlstate, \".\")\n        return\nend\n\nngx.say(\"table cats created.\")\n\nres, err, errno, sqlstate = db:query(\"insert into cats(name) \" .. \"values (\\'Bob\\'),(\\'\\'),(null)\")\nif not res then\n        ngx.say(\"bad request: \", err, \": \", errno, \": \", sqlstate, \".\")\n        return\nend\n\nngx.say(res.affected_rows, \" rows inserted into table cats \", \"(last insert id: \", res.insert_id, \")\")\n\nres, err, errno, sqlstate = db:query(\"select * from cats order by id asc\", 10)\nif not res then\n        ngx.say(\"bad result \", err, \": \", errno, \": \", sqlstate, \".\")\n        return\nend\n\nlocal cjson = require \"cjson\"\nngx.say(\"result: \", cjson.encode(res))\n\nlocal ok, err = db:set_keepalive(1000, 100)\nif not ok then\n        ngx.say(\"failed to set keepalive: \", err)\n        return\nend\n\n```\n\n## 4.lua 的 capture 和 capture_multi(子查询)\n\n**capture_multi 是 openresty 一个十分强大的功能**。它能极大的减少前端浏览器发送的http请求的数量，突破了浏览器对于同一个服务器并发请求数量的限制，因为他可以将前端的多个http请求减少为只要一个http请求到nginx，然后nginx使用capture_multi特性，对后端发起多个异步并发请求，然后统一将结果返回给前端。下面看一个例子：\n\n首先在nginx.conf中加入下面的 location 配置，并且配置好 nginx 访问 php 的配置：\n\n```\n        location /capture {\n            content_by_lua_file lua/capture.lua;\n            #access_by_lua_file lua/capture.lua;\n        }\n\n        location ~ \\.php$ {\n            root           html;\n            fastcgi_pass   127.0.0.1:9000;\n            fastcgi_index  index.php;\n            fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;\n            include        fastcgi_params;\n        }\n\n```\n\ncapture.lua 的代码如下：\n\n```\n[root@localhost html]# curl localhost/capture\nconnected to mysql.\ntable cats created.\n3 rows inserted into table cats (last insert id: 1)\nresult: [{\"name\":\"Bob\",\"id\":1},{\"name\":\"\",\"id\":2},{\"name\":null,\"id\":3}]\n\nset result: 1\ndog: an animal\n\nhello ngx_lua!!!!\n\nfalse\n200\nnil\n\n```\n\nngx.location.capture_multi{… …} 中的多个异步并发请求可以是 nginx.conf 中配置的 location(比如 /mysql_test, /redis_test, /lua)，也可以不是 location配置的路径，比如 index.php 就不是。index.php 就是一个简单的后台php 脚本。当然也可以是一个 java 实现的后台接口。\n\n## 5.openresty的缓存 lua_shared_dict\n\n定义一个缓存：\n\n在nginx的配置文件 nginx.conf 的 http 端下面加入指令：\n\n```\nlua_shared_dict ngx_cache 128m;\n```\n\n就定义了一个 名称为 ngx_cache 大小为128m的内存用于缓存，`注意该缓存是所有nginx work process所共享的`。\n\n在lua脚本中访问缓存：\n\n```\nlocal ngx_cache = ngx.shared.ngx_cache\nlocal value = ngx_cache:get(key)\n\nlocal succ, err, forcible = ngx_cache:set(key, value, exptime)\n\n```\n\n首先在 nginx.conf的server端中加入：\n\n        location /cache {\n            content_by_lua_file lua/cache.lua;\n        }\n编写cache.lua\n\n```c\n[root@localhost lua]# cat cache.lua\nlocal redis = require \"resty.redis\"\nlocal red = redis:new()\n\nfunction set_to_cache(key, value, exptime)\n        if not exptime then\n                exptime = 0\n        end\n        local ngx_cache = ngx.shared.ngx_cache\n        local succ, err, forcible = ngx_cache:set(key, value, exptime)\n        return succ\nend\n\nfunction get_from_cache(key)\n        local ngx_cache = ngx.shared.ngx_cache;\n        local value = ngx_cache:get(key)\n        if not value then\n                value = get_from_redis(key)\n                set_to_cache(key, value)\n                return value\n        end\n\n        ngx.say(\"get from cache.\")\n        return value\nend\n\nfunction get_from_redis(key)\n        red:set_timeout(1000)\n\n        local ok, err = red:connect(\"127.0.0.1\", 6379)\n        if not ok then\n                ngx.say(\"failed to connect: \", err)\n                return\n        end\n\n        local res, err = red:get(key)\n        if not res then\n                ngx.say(\"failed to get doy: \", err)\n                return ngx.null\n        end\n\n        ngx.say(\"get from redis.\")\n        return res\nend\n\nfunction set_to_redis(key, value)\n        red:set_timeout(1000)\n        local ok, err = red:connect(\"127.0.0.1\", 6379)\n        if not ok then\n                ngx.say(\"failed to connect: \", err)\n                return\n        end\n\n        local ok, err = red:set(key, value)\n        if not ok then\n                ngx.say(\"failed to set to redis: \", err)\n                return\n        end\n        return ok\nend\n\nset_to_redis('dog', \"Bob\")\nlocal rs = get_from_cache('dog')\nngx.say(rs)\n\n```\n\n可以使用 ab 测试一下rps(Requests per second):\n\n ab -n 1000 -c 100 -k http://127.0.0.1/cache\n\n## 6.解决缓存失效风暴 lua-resty-lock\n\n缓存失效风暴是指缓存因为时间过期而失效时，会导致所有的请求都去访问 后台的redis或者mysql，而导致CPU性能即刻增长的现象。所以关键是当缓存失效时，用lock保证只有一个线程去访问后台的redis或者mysql，然后更新缓存。需要使用到 lua-resty-lock 模块的加锁、解锁功能。\n\n首先在nginx.conf 的 http 端下面加入指令：\n\n```\nlua_shared_dict ngx_cache 128m;     # cache\nlua_shared_dict cache_lock 100k;    # lock for cache\n```\n\n然后在nginx.conf的server端中加入：\n\n```\n        location /cache_lock {\n            content_by_lua_file lua/cache_lock.lua;\n        }\n```\n\ncache_lock.lua代码：\n\n```c\n[root@localhost lua]# cat cache_lock.lua\nlocal redis = require \"resty.redis\"\nlocal red = redis:new()\nlocal resty_lock = require \"resty.lock\"\nlocal ngx_cache = ngx.shared.ngx_cache\n\nfunction set_to_cache(key, value, exptime)\n        if not exptime then\n                exptime = 0\n        end\n        local succ, err, forcible = ngx_cache:set(key, value, exptime)\n        return succ\nend\n\nfunction get_from_cache(key)\n        local ngx_cache = ngx.shared.ngx_cache;\n        local value = ngx_cache:get(key)\n        if not value then       -- cache miss\n                local lock = resty_lock:new(\"cache_lock\")\n                local elapsed, err = lock:lock(key)\n                if not elapsed then\n                        return fail(\"failed to acquire the lock: \", err)\n                end\n\n                value = get_from_redis(key)\n                if not value then\n                        local ok, err = lock:unlock()\n                        if not ok then\n                                return fail(\"failed to unlock: \", err)\n                        end\n                        ngx.say(\"no value found\")\n                        return\n                end\n\n                local ok, err = ngx_cache:set(key, value, 1)\n                if not ok then\n                        local ok, err = lock:unlock()\n                        if not ok then\n                                return fail(\"failed to unlock: \", err)\n                        end\n                        return faile(\"failed to update ngx_cache: \", err)\n                end\n\n                local ok, err = lock:unlock()\n                if not ok then\n                        return faile(\"failed to unlock: \", err)\n                end\n\n                return value\n        end\n\n        ngx.say(\"get from cache.\")\n        return value\nend\n\nfunction get_from_redis(key)\n        red:set_timeout(1000)\n\n        local ok, err = red:connect(\"127.0.0.1\", 6379)\n        if not ok then\n                ngx.say(\"failed to connect: \", err)\n                return\n        end\n\n        local res, err = red:get(key)\n        if not res then\n                ngx.say(\"failed to get doy: \", err)\n                return ngx.null\n        end\n\n        ngx.say(\"get from redis.\")\n        return res\nend\n\nfunction set_to_redis(key, value)\n        red:set_timeout(1000)\n        local ok, err = red:connect(\"127.0.0.1\", 6379)\n        if not ok then\n                ngx.say(\"failed to connect: \", err)\n                return\n        end\n\n        local ok, err = red:set(key, value)\n        if not ok then\n                ngx.say(\"failed to set to redis: \", err)\n                return\n        end\n        return ok\nend\n\nset_to_redis('dog', \"Bob\")\nlocal rs = get_from_cache('dog')\nngx.say(rs)\n```\n\n","tags":["nginx"],"categories":["nginx"]},{"title":"nginx学习笔记（—）","url":"%2F2020%2F03%2F24%2Fnginx%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E2%80%94%EF%BC%89.html","content":"    \n\n一个好人加入了战争，恶魔将会逃跑，上帝也会留下眼泪\n\n1.nginx主要学习的是配置文件\n\n首先说下正向代理与反向代理\n\n正向代理：比如我们想要访问国外的网站，我们不知道怎么到达，可以让代理服务器帮助，此时服务器只清楚请求来自哪个代理服务器，而不清楚具体请求者，而我们很明确的知道要访问谁\n\n反向代理：就是分布式，我们访问具体的网站却不知具体的服务器以为被代理到分布的一台机器上啦\n\n    #运行用户\n    user nobody;\n    #启动进程,通常设置成和cpu的数量相等\n    worker_processes  1;\n    >>nginx 主要核心模块俗称的main区\n    #全局错误日志及PID文件\n    #error_log  logs/error.log;\n    #error_log  logs/error.log  notice;\n    #error_log  logs/error.log  info;\n    \n    #pid        logs/nginx.pid;\n    \n    #工作模式及连接数上限\n    events { #events区\n        #epoll是多路复用IO(I/O Multiplexing)中的一种方式,\n        #仅用于linux2.6以上内核,可以大大提高nginx的性能\n        use   epoll; \n    \n        #单个后台worker process进程的最大并发链接数    \n        worker_connections  1024;\n    \n        # 并发总数是 worker_processes 和 worker_connections 的乘积\n        # 即 max_clients = worker_processes * worker_connections\n        # 在设置了反向代理的情况下，max_clients = worker_processes * worker_connections / 4  为什么\n        # 为什么上面反向代理要除以4，应该说是一个经验值\n        # 根据以上条件，正常情况下的Nginx Server可以应付的最大连接数为：4 * 8000 = 32000\n        #说明这里的8000指线程 4是进程\n        # worker_connections 值的设置跟物理内存大小有关\n        # 因为并发受IO约束，max_clients的值须小于系统可以打开的最大文件数\n        # 而系统可以打开的最大文件数和内存大小成正比，一般1GB内存的机器上可以打开的文件数大约是10万左右\n        # 我们来看看360M内存的VPS可以打开的文件句柄数是多少：\n        # $ cat /proc/sys/fs/file-max\n        # 输出 34336\n        # 32000 < 34336，即并发连接总数小于系统可以打开的文件句柄总数，这样就在操作系统可以承受的范围之内\n        # 所以，worker_connections 的值需根据 worker_processes 进程数目和系统可以打开的最大文件总数进行适当地进行设置\n        # 使得并发总数小于操作系统可以打开的最大文件数目\n        # 其实质也就是根据主机的物理CPU和内存进行配置\n        # 当然，理论上的并发总数可能会和实际有所偏差，因为主机还有其他的工作进程需要消耗系统资源。\n    \t# ulimit -SHn 65535\n    }\n    \n    \n    http {\n        #设定mime类型,类型由mime.type文件定义\n        include    mime.types; >这是引入\n        default_type  application/octet-stream;\n        #设定日志格式\n        log_format  main  '$remote_addr - $remote_user [$time_local] \"$request\" '\n                          '$status $body_bytes_sent \"$http_referer\" '\n                          '\"$http_user_agent\" \"$http_x_forwarded_for\"';\n    \n        access_log  logs/access.log  main;\n    \n        #sendfile 指令指定 nginx 是否调用 sendfile 函数（zero copy 方式）来输出文件，\n        #对于普通应用，必须设为 on,\n        #如果用来进行下载等应用磁盘IO重负载应用，可设置为 off，\n        #以平衡磁盘与网络I/O处理速度，降低系统的uptime.\n        sendfile     on;\n        #tcp_nopush     on;\n    \n        #连接超时时间\n        #keepalive_timeout  0;\n        keepalive_timeout  65;\n        tcp_nodelay     on;\n    \n        #开启gzip压缩\n        gzip  on;\n        gzip_disable \"MSIE [1-6].\";\n    \n        #设定请求缓冲\n        client_header_buffer_size    128k;\n        large_client_header_buffers  4 128k;\n    \n    \n        #设定虚拟主机配置\n        server {\n            #侦听80端口\n            listen    80;\n            #定义使用 www.nginx.cn访问\n            server_name  www.nginx.cn;\n    \n            #定义服务器的默认网站根目录位置\n            root html;\n    \n            #设定本虚拟主机的访问日志\n            access_log  logs/nginx.access.log  main;\n    \n            #默认请求\n            location / {\n                \n                #定义首页索引文件的名称\n                index index.php index.html index.htm;   \n    \n            }\n    \n            # 定义错误提示页面\n            error_page   500 502 503 504 /50x.html;\n            location = /50x.html {\n            }\n    \n            #静态文件，nginx自己处理\n            location ~ ^/(images|javascript|js|css|flash|media|static)/ {\n                \n                #过期30天，静态文件不怎么更新，过期可以设大一点，\n                #如果频繁更新，则可以设置得小一点。\n                expires 30d;\n            }\n    \n            #PHP 脚本请求全部转发到 FastCGI处理. 使用FastCGI默认配置.\n            location ~ .php$ {\n                fastcgi_pass 127.0.0.1:9000;\n                fastcgi_index index.php;\n                fastcgi_param  SCRIPT_FILENAME  $document_root$fastcgi_script_name;\n                include fastcgi_params;\n            }\n    \n            #禁止访问 .htxxx 文件\n                location ~ /.ht {\n                deny all;\n            }\n    \n        }\n    }\n\n机会总是留给那些有准备的人\n\n2.nginx命令\n\nnginx命令行参数\n\n  命令             \t说明                                      \n  -p prefix      \t设置 nginx prefix 路径，这是存储 nginx 服务文件的路径，默认为 /etc/nginx\n  -c filename    \t不使用默认配置文件，使用指定的配置文件(default: /etc/nginx/nginx.conf)\n  nginx          \t启动命令                                    \n  nginx -s stop  \t快速关闭 nginx                              \n  nginx -s quit  \t优雅的关闭 nginx                             \n  nginx -s reload\t重新加载配置                                  \n  nginx -s reopen\t重新打开日志文件                                \n  nginx  -t      \t检查配置文件                                  \n\n关于关闭进程补充一下linux进程知识 以nginx为例\n\nps -ef |grep nginx 找到进程然后 kill -9 进程号\n\nnetstat -ntlp  #查看当前所有tcp端口·\n\nnetstat -ntulp |grep 80 #查所有80端口的使用情况\n\nps aux | egrep '(PID|nginx)' kill -15 pid #中止\n\n也可以临时指定，支持热部署\n\n总之岁月漫长，然而值得等待\n\n3.upstream负载均衡块\n\nNginx的 HttpUpstreamModule提供对后端（backend）服务器的简单负载均衡。一个最简单的 upstream 写法如下：\n\n      upstream backend {\n        server backend1.example.com;\n        server backend2.example.com;\n        server backend3.example.com;\n    }\n    \n    server {\n        location / {\n            proxy_pass http://backend;\n        }\n    }\n    \n\n1. 通过 upstream 可以设定后端服务器，指定的方式可以是 IP 地址与端口、域名、UNIX 套接字（socket）。其中如果域名可以被解析为多个地址，则这些地址都作为 backend。下面举例说明\n\n     upstream backend {\n        server blog.csdn.net/poechant;\n        server 145.223.156.89:8090;\n        server unix:/tmp/backend3;\n    }\n\n2. 负载均衡策略\n   默认情况下，Nginx 会为你提供轮询作为负载均衡策略。但是这并不一定能够让你满意。比如，某一时段内的一连串访问都是由同一个用户 Michael 发起的，那么第一次 Michael 的请求可能是 backend2，\n   而下一次是 backend3，然后是 backend1、backend2、backend3…… 在大多数应用场景中，这样并不高效。当然，也正因如此，\n   Nginx 为你提供了一个按照 Michael、Jason、David 等等这些乱七八糟的用户的 IP 来 hash 的方式，\n   这样每个 client 的访问请求都会被甩给同一个后端服务器。具体的使用方式如下：\n    \n\n    upstream backend {\n        server blog.csdn.net/poechant down;\n        server 145.223.156.89:8090;\n        server unix:/tmp/backend3;\n    } \n\n还可以使用指定权重（weight）的方式，如下：\n\n     upstream backend {\n        server backend1.example.com;\n        server 123.321.123.321:456 weight=4;\n    } \n\n默认情况下 weight 为 1，对于上面的例子，第一个 server 的权重取默认值 1，第二个是 4，所以相当于第一个 server 接收 20% 的请求，第二接收 80% 的。要注意的是 weight 与 ip_hash 是不能同时使用的，原因很简单，他们是不同且彼此冲突的策略\n\nurl_hash（第三方）\n\n按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。\n\n注意：在upstream中加入hash语句，server语句中不能写入weight等其他的参数，hash_method是使用的hash算法。\n\n    upstream resinserver{ \n          server 10.0.0.10:7777; \n          server 10.0.0.11:8888; \n          hash $request_uri; \n          hash_method crc32; \n    }\n\npstream还可以为每个设备设置状态值，这些状态值的含义分别如下：\n\ndown 表示单前的server暂时不参与负载.\n\nweight 默认为1.weight越大，负载的权重就越大。\n\nmax_fails ：允许请求失败的次数默认为1.当超过最大次数时，返回proxy_next_upstream 模块定义的错误.\n\nfail_timeout : max_fails次失败后，暂停的时间。\n\nbackup： 其它所有的非backup机器down或者忙的时候，请求backup机器。所以这台机器压力会最轻。\n\n3. 重试策略\n\n可以为每个 backend 指定最大的重试次数，和重试时间间隔。所使用的关键字是 max_fails 和 fail_timeout。如下所示：\n\n    upstream backend {\n    server backend1.example.com weight=5;\n    server 54.244.56.3:8081 max_fails=3 fail_timeout=30s;\n    } \n\n在上例中，最大失败次数为 3，也就是最多进行 3 次尝试，且超时时间为 30秒。max_fails 的默认值为 1，fail_timeout 的默认值是 10s。传输失败的情形，由 proxy_next_upstream 或 fastcgi_next_upstream 指定。而且可以使用 proxy_connect_timeout 和 proxy_read_timeout 控制 upstream 响应时间。\n\n有一种情况需要注意，就是 upstream 中只有一个 server 时，max_fails 和 fail_timeout 参数可能不会起作用。导致的问题就是 nginx 只会尝试一次 upstream 请求，如果失败这个请求就被抛弃了 : ( ……解决的方法，比较取巧，就是在 upstream 中将你这个可怜的唯一 server 多写几次，如下：\n\n    upstream backend {\n    server backend.example.com max_fails fail_timeout=30s;\n    server backend.example.com max_fails fail_timeout=30s;\n    server backend.example.com max_fails fail_timeout=30s;\n    } \n\n4. 备机策略\n\n从 Nginx 的 0.6.7 版本开始，可以使用“backup”关键字。当所有的非备机（non-backup）都宕机（down）或者繁忙（busy）的时候，就只使用由 backup 标注的备机。必须要注意的是，backup 不能和 ip_hash 关键字一起使用。举例如下：\n\n    upstream backend {\n    server backend1.example.com;\n    server backend2.example.com backup;\n    server backend3.example.com;\n    }\n\n4.localtion指令详解\n\n    Nginx的HTTP配置主要包括三个区块，结构如下：\n    http { //这个是协议级别\n    　　include mime.types;\n    　　default_type application/octet-stream;\n    　　keepalive_timeout 65;\n    　　gzip on;\n    　　　　server { //这个是服务器级别\n    　　　　　　listen 80;\n    　　　　　　server_name localhost;\n    　　　　　　　　location / { //这个是请求级别\n    　　　　　　　　　　root html;\n    　　　　　　　　　　index index.html index.htm;\n    　　　　　　　　}\n    　　　　　　}\n    }\n\nlocation区段\n\n通过指定模式来与客户端请求的URI相匹配，基本语法如下：location [=|~|~*|^~|@] pattern{……}\n\n1、没有修饰符 表示：必须以指定模式开始，如：\n\n    server {\n    　　server_name baidu.com;\n    　　location /abc {\n    　　　　……\n    　　}\n    }\n    \n    \n    那么，如下是对的：\n    http://baidu.com/abc\n    http://baidu.com/abc?p1\n    http://baidu.com/abc/\n    http://baidu.com/abcde\n\n2、=表示：必须与指定的模式精确匹配\n\n    server {\n    server_name sish\n    　　location = /abc {\n    　　　　……\n    　　}\n    }\n    那么，如下是对的：\n    http://baidu.com/abc\n    http://baidu.com/abc?p1\n    如下是错的：\n    http://baidu.com/abc/\n    http://baidu.com/abcde\n\n3、~ 表示：指定的正则表达式要区分大小写\n\n    server {\n    server_name baidu.com;\n    　　location ~ ^/abc$ {\n    　　　　……\n    　　}\n    }\n    那么，如下是对的：\n    http://baidu.com/abc\n    http://baidu.com/abc?p1=11&p2=22\n    如下是错的：\n    http://baidu.com/ABC\n    http://baidu.com/abc/\n    http://baidu.com/abcde\n\n4、~* 表示：指定的正则表达式不区分大小写\n\n    server {\n    server_name baidu.com;\n    location ~* ^/abc$ {\n    　　　　……\n    　　}\n    }\n    那么，如下是对的：\n    http://baidu.com/abc\n    http://baidu..com/ABC\n    http://baidu..com/abc?p1=11&p2=22\n    如下是错的：\n    http://baidu..com/abc/\n    http://baidu..com/abcde\n\n5、^~ 类似于无修饰符的行为，也是以指定模式开始，不同的是，如果模式匹配，\n那么就停止搜索其他模式了。\n6、@ ：定义命名location区段，这些区段客户段不能访问，只可以由内部产生的请\n求来访问，如try_files或error_page等\n\n    location  = / {\n      # 只匹配请求 \"/\"\n      [ configuration A ] \n    }\n    location  / {\n      # 匹配任何请求，因为所有请求都是以\"/\"开始\n      # 但是更长字符匹配或者正则表达式匹配会优先匹配\n      [ configuration B ] \n    }\n    location /documents/ {\n      # 匹配所有 /documents/ 开头的请求，在没有正则表达\n      # 式匹配时选择该locaiton\n      [ configuration C ]\n    }\n    location ^~ /images/ {\n      # 匹配任何以 /images/ 开始的请求，并停止匹配其它location\n      [ configuration D ] \n    }E\n    location ~* .(gif|jpg|jpeg)$ {\n      # 匹配以 gif, jpg, or jpeg结尾的请求. \n      # 但是所有 /images/ 目录的请求将由 [Configuration D]处理.   \n      [ configuration E ] \n    }\n    请求URI例子:\n    \n    / -> 匹配A\n    /index.html -> 匹配B\n    /documents/a.html -> 匹配C\n    /images/1.gif -> 匹配D\n    /documents/1.jpg -> 匹配E\n\n查找顺序和优先级\n1：带有“=“的精确匹配优先\n2：没有修饰符的精确匹配\n3：正则表达式按照他们在配置文件中定义的顺序\n4：带有“^~”修饰符的，开头匹配\n5：带有“~” 或“~*” 修饰符的，如果正则表达式与URI匹配\n6：没有修饰符的，如果指定字符串与URI开头匹配\n\nroot 、alias指令区别\n\n    location /img/ {\n        alias /var/www/image/;\n    }\n\n    #若按照上述配置的话，则访问/img/目录里面的文件时，ningx会自动去/var/www/image/目录找文件\n\n    location /img/ {\n        root /var/www/image;\n    }\n\n    若按照这种配置的话，则访问/img/目录下的文件时，nginx会去/var/www/image/img/目录下找文件。] \n\nalias是一个目录别名的定义，root则是最上层目录的定义。\n\n还有一个重要的区别是alias后面必须要用“/”结束，否则会找不到文件的。。。而root则可有可无~~\n","tags":["nginx"],"categories":["nginx"]},{"title":"春来","url":"%2F2020%2F03%2F24%2F%E6%98%A5%E6%9D%A5.html","content":"北方大雪纷飞，南国大雨连绵。果真是，往昔不可追，时令不可违。\n\n《道德经》有句：“飘风不终朝，骤雨不终日。”天地万物皆有其规律，开落有序，荣枯有定。当下的雨雪，以及灾事，亦是不能久长。\n\n“春日迟迟，采蘩祁祁。”这个春天，虽然来得缓慢，却会如约而至。且比之从前任何一个春天，更加令人期待，温暖有情。\n\n那时的人间，杏雨梨云，群莺乱飞。满目春光，无人做主。而我，也该归去梅庄，剪枝插瓶，春水煎茶。\n\n封城已有半月余，等待成了信仰。这一年，许多人的命运被改写，但都学会了坦然以待。而我，有一壶酒，一盏茶，足矣消闷解烦。任凭世事飞沙走石，我自是风雨不动，慌乱不惊。\n\n“蜉蝣之羽，衣裳楚楚。心之忧矣，于我归处？”说不劳神忧心，是虚话。想当年杜工部忧国忧民，生出“安得广厦千万间，大庇天下寒士俱欢颜”之叹。我虽薄弱，却亦有此心。\n\n太湖水畔的山庄，也为此搁浅，等候时光给予美妙的安排。往后余生，归去林泉，种菜伺花，无可更改。愿有一畦菜地，供养苍生，几片瓦当，庇护万民。\n\n寸阴可贵，一刻千金。静下来的时候，许多人对生命有了新的认知，对未知的将来，重新有了念想。不再执迷，亦不抱怨，因为浩浩荡荡的一辈子，有无数的风雨消磨，我们要活得心安境宽，有情有味。\n\n无论光阴几何，人的一生，终要做一件比生命，更为宏伟的事业。过些时日，我又该生火炙茶，采花酿酒，读书养气，写字谋生。\n\n世上的人，都有来时，亦有归处。有人愿化身石桥，受五百年的风吹日晒雨淋，只为一人打桥上经过。\n\n而我，愿做驿外断桥边的一株白梅，若人世的一剪清光，照彻凡尘每一个悲伤、迷惘的路人。\n","tags":["美文"],"categories":["心情"]}]